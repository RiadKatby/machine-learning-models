# التصنيف
سنركز هنا على نظم التصنيف في تعلم الآلة

## قاعدة البيانات المعدلة من المعهد الوطني للمعايير والتكنولوجيا - MNIST
سنعمل في هذا الفصل على مجموعة بيانات MNIST، وهي عبارة عن 70,000 صورة صغيرة من الأرقام المكتوبة بخط اليد من قبل طلاب المدارس الثانوية وموظفي مكتب الإحصاء الأمريكي. ,تحمل كل صورة اسم الرقم الذي تمثله. إنها من أكثر مجموعات البيانات دراسة من قبل الباحثين، ويطلق عليها غالباً "Hello World" في تعلم الآلة، فكلما توصل أحدهم إلى خوارزمية تصنيف جديدة يبدأ بهذه المجموعة ليرى أداء خوارزميته عليها. يمكننا القول أنه ما من شخص بدأ بتعلم الآلة إلا وعمل على هذه المجموعة عاجلاً أم آجلاً.

يوفر Scikit-Learn العديد من الدوال التي تساعد على تنزيل مجموعات البيانات الشائعة وMINST واحدة منهن. يجلب الكود التالي مجموعة البيانات [^1]

```python
>>> from sklearn.datasets import fetch_openml
>>> mnist = fetch_openml('mnist_784', version=1)
>>> mnist.keys()
dict_keys(['data', 'target', 'feature_names', 'DESCR', 'details', 'categories', 'url'])
```

تحتوي مجموعات البيانات التي تُحمل بواسطة Scikit-Learn عامةً على بنية قاموس موحدة تقريباً، كما يلي
* DESCR يصف مجموعة البيانات
* data يحتوي على مصفوفة سطورها الأمثلة وأعمدتها الميزات
* target يحتوي مصفوفة أسماء الأمثلة

لنلقي نظرة على هذه المصفوفات:

```python
>>> X, y = mnist["data"], mnist["target"]
>>> X.shape
(70000, 784)
>>> y.shape
(70000,)
```

لدينا 70,000 صورة، ولكل صورة 784 ميزة، حيث أن كل صورة هي 28x28 بكسل، وكل ميزة تمثل بكسل واحد يأخذ قيمة بين ال 0 أبيض وال 255 أسود.

لنلقي نظرة على أحد هذه الأرقام الموجودة في مجموعة البيانات. كل ما علينا فعله هو أخذ أحد متجهات الأمثلة، وإعادة تشكله إلى مصفوفة 28x28، ثم عرضه باستخدام `imshow()` الموجودة في Matplotlib:

```python
import matplotlib as mpl
import matplotlib.pyplot as plt

some_digit = X[0]
some_digit_image = some_digit.reshape(28, 28)

plt.imshow(some_digit_image, cmap = mpl.cm.binary, interpolation="nearest")
plt.axis("off")
plt.show()
```

كما نرى فإنه يشبه الرقم 5، وهذا مايخبرنا به اسمه بالفعل:

```python
>>> y[0]
'5'
```

لاحظ أن الاسم عبارة عن نص string، وغالباً ما تكون الأرقام أفضل في هذا المجال لذا دعونا نحول y إلى الأعداد الصحيحة:

```python
>>> y = y.astype(np.uint8)
```

إنظر الشكل 3-1 الذي يحتوي بعد الصور الأخرى من مجموعة بيانات MNIST سيعطيك احساساً بتعقيد مهمة التصنيف.

<<>>
الشكل 3-1 بعض الأرقام من مجموعة بيانات MNIST

تذكر! يجب علينا دائماً إنشاء مجموعة اختبار ووضعها جانباً قبل التعمق في تفحص البيانات. لحسن الحظ فقد قُسمت هذه المجموعة بالفعل إلى مجموعة تدريب (أول 60,000 صورة) ومجموعة اختبار (آخر 10,000 صورة):

```python
X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]
```

أحد النقاط الجيدة أيضاً في Scikit-Learn أنها تعطينا مجموعة التدريب وقد تم خلطها بالفعل مسبقاً بما يضمن تشابه كل طيات التحقق المتقاطع (فلا نريد أن نفقد بعض الأرقام في احدى الطيات). ذلك أن بعض خوارزميات التعلم حساسة لترتيب أمثلة التدريب، وستعمل بشكل سيء إذا حصلت على العديد من الأمثلة المتشابهة على التوالي. فيضمن خلط مجموعة البيانات عدم حدوث ذلك[^2].

## تدريب مصنف ثنائي
سنبسط المشكلة حالياً ونحاول فقط تحديد رقم واحد وليكون على سبيل المثال الرقم 5. سيكون نموذج الكشف عن الرقم 5 هذا مثالاً لمصنف ثنائي، قادر على التمييز بين صنفين فقط، إما 5 أو ليس 5. سنقوم فيما يلي بتجهيز المتجهات الهدف لهذا المصنف لتكون على صنفين فقط:

```python
y_train_5 = (y_train == 5) # True for all 5s, False for all other digits.
y_test_5 = (y_test == 5)
```

يعتبر Stochastic Gradient Descent (SGD) من أفضل خوارزميات التصنيف التي يمكن أن نبدء بها، ولدى Scikit-Learn فئة خاصة له بإسم `SGDClassifier`. ويتميز بقدرته على العمل بكفاءة مع مجموعات البيانات الكبيرة. إضافة إلى تعامله مع أمثلة مجموعة التدريب واحداً تلو الآخر ما يجعله مناسباً أيضاً للتعلم المستمر online كما سنرى لاحقاً. لننشئ مصنف من فئة `SGDClassifier` وندربه على مجموعة التدريب بأكملها:

```python
from sklearn.linear_model import SGDClassifier

sgd_clf = SGDClassifier(random_state=42)
sgd_clf.fit(X_train, y_train_5)
```

*ملاحظة* يعتمد `SGDClassifier` على العشوائية أثناء التدريب (ومن هنا جاء اسمه) فإذا كنت تريد نتائج قابلة للتكرار عليك تحديد قيمة المعامل `random_state`.

والآن يمكننا استخدام هذا المصنف لاكتشاف صور الرقم 5:

```python
>>> sgd_clf.predict([some_digit])
array([ True])
```

يخمن المصنف أن هذه الصورة تمثل الرقم 5 وهو على صواب بهذه الحالة بالذات، والآن لنقيّم أداء هذا النموذج.

## مقاييس الأداء
تقييم أداء المصنفات غالباً ما يكون أصعب من تقييم اداء الإنحدار، لذلك سنبذل جزء كبيراً من هذا الفصل على هذا الموضوع، فهناك العديد من مقاييس الأداء، لذا حضر فنجان قهوة آخر واستعد لتعلم العديد من المفاهيم والأختصارات الجديدة.

### قياس الدقة باستخدام التحقق المتقاطع
استخدام التحقق المتقاطع من الطرق الجيدة لتقييم أداء النموذج، تماماً كما فعلنا في الفصل الثاني.

#### تنفيذ التحقق المتقاطع
نحتاج إلى المزيد من التحكم في عملية التحقق المتقاطع في بعض الأحيان أكثر مما هو جاهز وموجود في Scikit-Learn. في هذه الحالات يمكننا كتابة دالة التحقق المتقاطع بأنفسنا، سيكون الكود واضح ومباشر، يقوم الكود التالي بنفس الشيء تقريباً مثل وظيفة `cross_val_score()` في Scikit-Learn ويطبع نفس النتيجة:

```python
from sklearn.model_selection import StratifiedKFold
from sklearn.base import clone

skfolds = StratifiedKFold(n_splits=3, random_state=42)

for train_index, test_index in skfolds.split(X_train, y_train_5):
    clone_clf = clone(sgd_clf)
	 X_train_folds = X_train[train_index]
	 y_train_folds = y_train_5[train_index]
	 X_test_fold = X_train[test_index]
	 y_test_fold = y_train_5[test_index]
	 
	 clone_clf.fit(X_train_folds, y_train_folds)
	 y_pred = clone_clf.predict(X_test_fold)
	 n_correct = sum(y_pred == y_test_fold)
	 print(n_correct / len(y_pred)) # prints 0.9502, 0.96565 and 0.96495
```

تقوم الفئة `StratifiedKFold` بأخذ عينات طبقية (كما وضحنا في الفصل الثاني) لإنتاج طيات تحتوي على نسبة متماثلة من كل فئة. ينسخ الكود التالي المصنف `sgd_clf` مع كل تكرار، ثم يُدرب هذا المصنف على احد طيات التدريب، ويقوم بالتنبؤات على احدى طيات الاختبار، ثم يحسب عدد التنبؤات الصحيحة ويطبع نسبتها.

والآن لنقييم النموذج `SGDClassifier` باستخدام الدالة `cross_val_score()` التي تؤدي التحقق المتقاطع على ثلاث طيات. تذكر أن التحقق المتقاطع بثلاث طيات يعني: تقسيم مجموعة التدريب إلى ثلاثة طيات، وتدريب المصنف على طيتين ثم عمل التنبؤات وتقييمها على الطية المتبقية باستخدام النموذج الذي قمنا بتدريبه على الطيتين السابقتين.

```python
>>> from sklearn.model_selection import cross_val_score
>>> cross_val_score(sgd_clf, X_train, y_train_5, cv=3, scoring="accuracy")
array([0.96355, 0.93795, 0.95615])
```
والآن، رائع! فالدقة أعلى من 93% (نسبة التنبؤات الصحيحة) على جميع طيات التحقق المتقاطع.
عمل رائع كما يبدو, صحيح؟ لكن قبل أن تشعر بالحماس الشديد، لنلقي نظرة على مصنف غبي جداً سنبنيه لكي يتنبأ بأي صورة نعطيه إيها على أنها لا تحتوي الرقم 5، بمعنى أنه يضعها بفئة not-5.

```python
from sklearn.base import BaseEstimator

class Never5Classifier(BaseEstimator):
    def fit(self, X, y=None):
        pass
    def predict(self, X):
        return np.zeros((len(X), 1), dtype=bool)
```

هل تستطيع تخمين دقة هذا النموذج الغبي؟ دعنا نرى:

```python
>>> never_5_clf = Never5Classifier()
>>> cross_val_score(never_5_clf, X_train, y_train_5, cv=3, scoring="accuracy")
array([0.91125, 0.90855, 0.90915])
```

تبلغ دقته أكثر من 90% وهذه صحيح ذلك أن حوالي 10% فقط من الصور تحتوي على الرقم 5 حقيقة، لذلك إذا خمنت دائماً أن الصورة لا تحتوي على الرقم 5، فستكون مصيباً وعلى حق في 90% من الحالات.

وهذا بالضبط سبب عدم اعتبار الدقة عموماً كمقياس أداء للمصنفات، خاصة عندما نتعامل مع مجموعات بيانات منحرفة (عندما تكون بعض الفئات أكثر تكراراً من غيرها).


# فهرس الترجمة
| المصطلح | الترجمة |
| ---------- |  ---------- |
| class    | فئة      |
| cross-validation    | التحقق المتقاطع |
| k-folds    | الطيات |
| Stratified Sampling | أخذ عينات طبقية |
| skewed dataset | مجموعة بيانات منحرفة |

[^note]:
[^1]: يخزن Scikit-Learn مجموعات البيانات التي يتم تنزيلها بشكل افتراضي في هذا المسار $HOME/scikit_learn_data.
[^2]: قد يكون خلط الأمثلة فكرة سيئة في بعض الأحيان، على سبيل المثال: إذا كنت تعمل على بيانات السلاسل الزمنية (مثل أسعار سوق الأسهم أو الأحوال الجوية).